"""
æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿ç»„ä»¶
æä¾›å®æ—¶æ€§èƒ½ç›‘æ§çš„Web UIç•Œé¢
"""

import json
import gradio as gr
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple

from .metrics_service import get_metrics_service, MetricsService
from .health_check_service import get_health_check_service, HealthCheckService, HealthStatus
from ..logging.logging_service import get_logging_service, ILoggingService


class PerformanceDashboard:
    """æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿"""

    def __init__(self,
                 metrics_service: Optional[MetricsService] = None,
                 health_service: Optional[HealthCheckService] = None,
                 logger_service: Optional[ILoggingService] = None):
        """åˆå§‹åŒ–æ€§èƒ½ä»ªè¡¨æ¿

        Args:
            metrics_service: æŒ‡æ ‡æœåŠ¡å®ä¾‹
            health_service: å¥åº·æ£€æŸ¥æœåŠ¡å®ä¾‹
            logger_service: æ—¥å¿—æœåŠ¡å®ä¾‹
        """
        self._metrics_service = metrics_service or get_metrics_service()
        self._health_service = health_service or get_health_check_service()
        self._logger = logger_service or get_logging_service()

        # UIç»„ä»¶
        self._components = {}

        self._logger.info("æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿åˆå§‹åŒ–å®Œæˆ")

    def create_dashboard(self) -> gr.Blocks:
        """åˆ›å»ºä»ªè¡¨æ¿UI

        Returns:
            Gradio Blocksç»„ä»¶
        """
        with gr.Blocks(title="æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿", theme=gr.themes.Soft()) as dashboard:
            gr.Markdown("# ğŸš€ ç³»ç»Ÿæ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿")

            with gr.Tabs():
                # ç³»ç»Ÿå¥åº·çŠ¶æ€é¡µ
                with gr.TabItem("ğŸ©º ç³»ç»Ÿå¥åº·", id="health"):
                    self._create_health_tab()

                # æ€§èƒ½æŒ‡æ ‡é¡µ
                with gr.TabItem("ğŸ“Š æ€§èƒ½æŒ‡æ ‡", id="metrics"):
                    self._create_metrics_tab()

                # RAGç‰¹å®šæŒ‡æ ‡é¡µ
                with gr.TabItem("ğŸ¤– RAGæŒ‡æ ‡", id="rag"):
                    self._create_rag_metrics_tab()

                # ç³»ç»Ÿèµ„æºé¡µ
                with gr.TabItem("ğŸ’» ç³»ç»Ÿèµ„æº", id="resources"):
                    self._create_resources_tab()

        return dashboard

    def _create_health_tab(self):
        """åˆ›å»ºå¥åº·çŠ¶æ€æ ‡ç­¾é¡µ"""
        with gr.Row():
            with gr.Column(scale=2):
                gr.Markdown("## æ•´ä½“å¥åº·çŠ¶æ€")

                # æ•´ä½“çŠ¶æ€æ˜¾ç¤º
                self._components['overall_status'] = gr.Markdown(
                    "ğŸ”„ æ­£åœ¨æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€...",
                    elem_id="overall-status"
                )

                # ç³»ç»Ÿè¿è¡Œæ—¶é—´
                self._components['uptime'] = gr.Markdown(
                    "â±ï¸ ç³»ç»Ÿè¿è¡Œæ—¶é—´: è®¡ç®—ä¸­...",
                    elem_id="system-uptime"
                )

            with gr.Column(scale=1):
                # å¥åº·æ£€æŸ¥æŒ‰é’®
                refresh_health_btn = gr.Button("ğŸ”„ åˆ·æ–°å¥åº·çŠ¶æ€", variant="primary")

        # ç»„ä»¶å¥åº·è¯¦æƒ…
        gr.Markdown("## ç»„ä»¶å¥åº·è¯¦æƒ…")
        self._components['component_health'] = gr.JSON(
            label="ç»„ä»¶çŠ¶æ€è¯¦æƒ…",
            show_label=True
        )

        # ç»‘å®šäº‹ä»¶
        refresh_health_btn.click(
            fn=self._refresh_health_status,
            outputs=[
                self._components['overall_status'],
                self._components['uptime'],
                self._components['component_health']
            ]
        )

        # è‡ªåŠ¨åˆ·æ–°ï¼ˆæ¯30ç§’ï¼‰
        dashboard_refresh = gr.Timer(30)
        dashboard_refresh.tick(
            fn=self._refresh_health_status,
            outputs=[
                self._components['overall_status'],
                self._components['uptime'],
                self._components['component_health']
            ]
        )

    def _create_metrics_tab(self):
        """åˆ›å»ºæ€§èƒ½æŒ‡æ ‡æ ‡ç­¾é¡µ"""
        with gr.Row():
            with gr.Column(scale=3):
                gr.Markdown("## å®æ—¶æ€§èƒ½æŒ‡æ ‡")

                # æŒ‡æ ‡æœç´¢
                metric_search = gr.Textbox(
                    label="æŒ‡æ ‡åç§°è¿‡æ»¤",
                    placeholder="è¾“å…¥æŒ‡æ ‡åç§°è¿›è¡Œè¿‡æ»¤...",
                    value=""
                )

                # æŒ‡æ ‡æ•°æ®æ˜¾ç¤º
                self._components['metrics_data'] = gr.JSON(
                    label="æ€§èƒ½æŒ‡æ ‡æ•°æ®",
                    show_label=True
                )

            with gr.Column(scale=1):
                # æ§åˆ¶é¢æ¿
                gr.Markdown("### æ§åˆ¶é¢æ¿")

                refresh_metrics_btn = gr.Button("ğŸ”„ åˆ·æ–°æŒ‡æ ‡", variant="primary")
                export_metrics_btn = gr.Button("ğŸ“¥ å¯¼å‡ºæŒ‡æ ‡", variant="secondary")
                clear_metrics_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç†æŒ‡æ ‡", variant="stop")

                # æ¸…ç†é€‰é¡¹
                clear_hours = gr.Slider(
                    minimum=1,
                    maximum=72,
                    value=24,
                    step=1,
                    label="æ¸…ç†å¤šå°‘å°æ—¶å‰çš„æ•°æ®"
                )

        # æ€§èƒ½ç»Ÿè®¡æ‘˜è¦
        gr.Markdown("## æ€§èƒ½ç»Ÿè®¡æ‘˜è¦")
        self._components['performance_summary'] = gr.Markdown(
            "ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡æ­£åœ¨åŠ è½½..."
        )

        # ç»‘å®šäº‹ä»¶
        refresh_metrics_btn.click(
            fn=self._refresh_metrics,
            inputs=[metric_search],
            outputs=[
                self._components['metrics_data'],
                self._components['performance_summary']
            ]
        )

        export_metrics_btn.click(
            fn=self._export_metrics,
            outputs=[gr.File()]
        )

        clear_metrics_btn.click(
            fn=self._clear_metrics,
            inputs=[clear_hours],
            outputs=[self._components['metrics_data']]
        )

        metric_search.change(
            fn=self._refresh_metrics,
            inputs=[metric_search],
            outputs=[
                self._components['metrics_data'],
                self._components['performance_summary']
            ]
        )

    def _create_rag_metrics_tab(self):
        """åˆ›å»ºRAGç‰¹å®šæŒ‡æ ‡æ ‡ç­¾é¡µ"""
        gr.Markdown("## ğŸ¤– RAGç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡")

        with gr.Row():
            with gr.Column():
                # RAGå“åº”æ—¶é—´ç»Ÿè®¡
                self._components['rag_response_time'] = gr.Markdown(
                    "â±ï¸ RAGå“åº”æ—¶é—´ç»Ÿè®¡æ­£åœ¨åŠ è½½..."
                )

                # RAGæŸ¥è¯¢ç»Ÿè®¡
                self._components['rag_query_stats'] = gr.Markdown(
                    "ğŸ“Š RAGæŸ¥è¯¢ç»Ÿè®¡æ­£åœ¨åŠ è½½..."
                )

            with gr.Column():
                # æ£€ç´¢è´¨é‡æŒ‡æ ‡
                self._components['rag_retrieval_quality'] = gr.Markdown(
                    "ğŸ¯ æ£€ç´¢è´¨é‡æŒ‡æ ‡æ­£åœ¨åŠ è½½..."
                )

                # ä¸Šä¸‹æ–‡é•¿åº¦ç»Ÿè®¡
                self._components['rag_context_stats'] = gr.Markdown(
                    "ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦ç»Ÿè®¡æ­£åœ¨åŠ è½½..."
                )

        # åˆ·æ–°æŒ‰é’®
        refresh_rag_btn = gr.Button("ğŸ”„ åˆ·æ–°RAGæŒ‡æ ‡", variant="primary")

        refresh_rag_btn.click(
            fn=self._refresh_rag_metrics,
            outputs=[
                self._components['rag_response_time'],
                self._components['rag_query_stats'],
                self._components['rag_retrieval_quality'],
                self._components['rag_context_stats']
            ]
        )

    def _create_resources_tab(self):
        """åˆ›å»ºç³»ç»Ÿèµ„æºæ ‡ç­¾é¡µ"""
        gr.Markdown("## ğŸ’» ç³»ç»Ÿèµ„æºç›‘æ§")

        with gr.Row():
            with gr.Column():
                # CPUå’Œå†…å­˜ä½¿ç”¨ç‡
                self._components['cpu_memory'] = gr.Markdown(
                    "ğŸ–¥ï¸ CPUå’Œå†…å­˜ä½¿ç”¨ç‡æ­£åœ¨åŠ è½½..."
                )

                # ç£ç›˜ä½¿ç”¨æƒ…å†µ
                self._components['disk_usage'] = gr.Markdown(
                    "ğŸ’¾ ç£ç›˜ä½¿ç”¨æƒ…å†µæ­£åœ¨åŠ è½½..."
                )

            with gr.Column():
                # ç½‘ç»œæŒ‡æ ‡
                self._components['network_stats'] = gr.Markdown(
                    "ğŸŒ ç½‘ç»œç»Ÿè®¡æ­£åœ¨åŠ è½½..."
                )

                # è¿›ç¨‹ä¿¡æ¯
                self._components['process_info'] = gr.Markdown(
                    "âš™ï¸ è¿›ç¨‹ä¿¡æ¯æ­£åœ¨åŠ è½½..."
                )

        # åˆ·æ–°æŒ‰é’®
        refresh_resources_btn = gr.Button("ğŸ”„ åˆ·æ–°èµ„æºä¿¡æ¯", variant="primary")

        refresh_resources_btn.click(
            fn=self._refresh_system_resources,
            outputs=[
                self._components['cpu_memory'],
                self._components['disk_usage'],
                self._components['network_stats'],
                self._components['process_info']
            ]
        )

    def _refresh_health_status(self) -> Tuple[str, str, Dict]:
        """åˆ·æ–°å¥åº·çŠ¶æ€

        Returns:
            (æ•´ä½“çŠ¶æ€, è¿è¡Œæ—¶é—´, ç»„ä»¶è¯¦æƒ…)
        """
        try:
            # è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€
            system_health = self._health_service.check_health()

            # æ ¼å¼åŒ–æ•´ä½“çŠ¶æ€
            status_emoji = {
                HealthStatus.HEALTHY: "âœ…",
                HealthStatus.DEGRADED: "âš ï¸",
                HealthStatus.UNHEALTHY: "âŒ",
                HealthStatus.UNKNOWN: "â“"
            }

            overall_status = f"{status_emoji.get(system_health.overall_status, 'â“')} " \
                           f"ç³»ç»ŸçŠ¶æ€: **{system_health.overall_status.value.upper()}**"

            # æ ¼å¼åŒ–è¿è¡Œæ—¶é—´
            if system_health.uptime:
                hours = int(system_health.uptime // 3600)
                minutes = int((system_health.uptime % 3600) // 60)
                uptime_str = f"â±ï¸ ç³»ç»Ÿè¿è¡Œæ—¶é—´: **{hours}å°æ—¶ {minutes}åˆ†é’Ÿ**"
            else:
                uptime_str = "â±ï¸ ç³»ç»Ÿè¿è¡Œæ—¶é—´: æœªçŸ¥"

            # è½¬æ¢ç»„ä»¶è¯¦æƒ…ä¸ºå­—å…¸
            component_details = system_health.to_dict()

            return overall_status, uptime_str, component_details

        except Exception as e:
            self._logger.error("åˆ·æ–°å¥åº·çŠ¶æ€å¤±è´¥", exception=e)
            return "âŒ å¥åº·çŠ¶æ€æ£€æŸ¥å¤±è´¥", "â±ï¸ ç³»ç»Ÿè¿è¡Œæ—¶é—´: æœªçŸ¥", {}

    def _refresh_metrics(self, search_pattern: str = "") -> Tuple[Dict, str]:
        """åˆ·æ–°æ€§èƒ½æŒ‡æ ‡

        Args:
            search_pattern: æœç´¢æ¨¡å¼

        Returns:
            (æŒ‡æ ‡æ•°æ®, æ€§èƒ½æ‘˜è¦)
        """
        try:
            # è·å–æŒ‡æ ‡æ•°æ®
            metrics_data = self._metrics_service.get_metrics(search_pattern if search_pattern else None)

            # ç”Ÿæˆæ€§èƒ½æ‘˜è¦
            summary_lines = []

            if 'performance_stats' in metrics_data:
                stats = metrics_data['performance_stats']
                summary_lines.append(f"ğŸ“Š **æ€»æŒ‡æ ‡æ•°**: {stats.get('total_metrics_recorded', 0)}")
                summary_lines.append(f"âš¡ **æ¯ç§’æŒ‡æ ‡**: {stats.get('metrics_per_second', 0):.2f}")

            if 'counters' in metrics_data:
                counter_count = len(metrics_data['counters'])
                summary_lines.append(f"ğŸ”¢ **è®¡æ•°å™¨æ•°é‡**: {counter_count}")

            if 'time_series' in metrics_data:
                ts_count = len(metrics_data['time_series'])
                summary_lines.append(f"ğŸ“ˆ **æ—¶é—´åºåˆ—**: {ts_count}")

            if 'histograms' in metrics_data:
                hist_count = len(metrics_data['histograms'])
                summary_lines.append(f"ğŸ“Š **ç›´æ–¹å›¾**: {hist_count}")

            summary_lines.append(f"ğŸ• **æœ€åæ›´æ–°**: {datetime.now().strftime('%H:%M:%S')}")

            performance_summary = "\n".join(summary_lines)

            return metrics_data, performance_summary

        except Exception as e:
            self._logger.error("åˆ·æ–°æŒ‡æ ‡å¤±è´¥", exception=e)
            return {}, "âŒ æŒ‡æ ‡åˆ·æ–°å¤±è´¥"

    def _export_metrics(self) -> Optional[str]:
        """å¯¼å‡ºæŒ‡æ ‡æ•°æ®

        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            import tempfile
            import os

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_dir = tempfile.gettempdir()
            file_path = os.path.join(temp_dir, f"metrics_export_{timestamp}.json")

            # å¯¼å‡ºæŒ‡æ ‡
            if self._metrics_service.export_metrics(file_path):
                return file_path
            else:
                return None

        except Exception as e:
            self._logger.error("å¯¼å‡ºæŒ‡æ ‡å¤±è´¥", exception=e)
            return None

    def _clear_metrics(self, hours: int) -> Dict:
        """æ¸…ç†æŒ‡æ ‡æ•°æ®

        Args:
            hours: æ¸…ç†å¤šå°‘å°æ—¶å‰çš„æ•°æ®

        Returns:
            æ¸…ç†åçš„æŒ‡æ ‡æ•°æ®
        """
        try:
            # æ¸…ç†æŒ‡æ ‡
            self._metrics_service.clear_metrics(hours)

            # è¿”å›æ›´æ–°åçš„æŒ‡æ ‡æ•°æ®
            return self._metrics_service.get_metrics()

        except Exception as e:
            self._logger.error("æ¸…ç†æŒ‡æ ‡å¤±è´¥", exception=e)
            return {}

    def _refresh_rag_metrics(self) -> Tuple[str, str, str, str]:
        """åˆ·æ–°RAGæŒ‡æ ‡

        Returns:
            (å“åº”æ—¶é—´, æŸ¥è¯¢ç»Ÿè®¡, æ£€ç´¢è´¨é‡, ä¸Šä¸‹æ–‡ç»Ÿè®¡)
        """
        try:
            metrics_data = self._metrics_service.get_metrics("rag")

            # RAGå“åº”æ—¶é—´ç»Ÿè®¡
            response_time_text = "â±ï¸ **RAGå“åº”æ—¶é—´ç»Ÿè®¡**\n"
            if 'histograms' in metrics_data and 'rag_response_time' in metrics_data['histograms']:
                stats = metrics_data['histograms']['rag_response_time']
                response_time_text += f"- å¹³å‡å“åº”æ—¶é—´: {stats['avg']:.2f}ç§’\n"
                response_time_text += f"- æœ€å¿«å“åº”: {stats['min']:.2f}ç§’\n"
                response_time_text += f"- æœ€æ…¢å“åº”: {stats['max']:.2f}ç§’\n"
                response_time_text += f"- æ€»æŸ¥è¯¢æ¬¡æ•°: {stats['count']}"
            else:
                response_time_text += "æš‚æ— å“åº”æ—¶é—´æ•°æ®"

            # RAGæŸ¥è¯¢ç»Ÿè®¡
            query_stats_text = "ğŸ“Š **RAGæŸ¥è¯¢ç»Ÿè®¡**\n"
            if 'counters' in metrics_data and 'rag_queries_total' in metrics_data['counters']:
                total_queries = metrics_data['counters']['rag_queries_total']
                query_stats_text += f"- æ€»æŸ¥è¯¢æ•°: {total_queries}\n"
                query_stats_text += f"- ä»Šæ—¥æŸ¥è¯¢æ•°: å¾…å®ç°\n"
                query_stats_text += f"- æŸ¥è¯¢æˆåŠŸç‡: å¾…å®ç°"
            else:
                query_stats_text += "æš‚æ— æŸ¥è¯¢ç»Ÿè®¡æ•°æ®"

            # æ£€ç´¢è´¨é‡æŒ‡æ ‡
            retrieval_quality_text = "ğŸ¯ **æ£€ç´¢è´¨é‡æŒ‡æ ‡**\n"
            if 'time_series' in metrics_data and 'rag_retrieval_count' in metrics_data['time_series']:
                retrieval_data = metrics_data['time_series']['rag_retrieval_count']
                if retrieval_data:
                    avg_retrieval = sum(d['value'] for d in retrieval_data) / len(retrieval_data)
                    retrieval_quality_text += f"- å¹³å‡æ£€ç´¢æ–‡æ¡£æ•°: {avg_retrieval:.1f}\n"
                    retrieval_quality_text += f"- æ£€ç´¢ç›¸å…³æ€§: å¾…å®ç°\n"
                    retrieval_quality_text += f"- å‘½ä¸­ç‡: å¾…å®ç°"
                else:
                    retrieval_quality_text += "æš‚æ— æ£€ç´¢æ•°æ®"
            else:
                retrieval_quality_text += "æš‚æ— æ£€ç´¢è´¨é‡æ•°æ®"

            # ä¸Šä¸‹æ–‡é•¿åº¦ç»Ÿè®¡
            context_stats_text = "ğŸ“ **ä¸Šä¸‹æ–‡é•¿åº¦ç»Ÿè®¡**\n"
            if 'time_series' in metrics_data and 'rag_context_length' in metrics_data['time_series']:
                context_data = metrics_data['time_series']['rag_context_length']
                if context_data:
                    avg_length = sum(d['value'] for d in context_data) / len(context_data)
                    max_length = max(d['value'] for d in context_data)
                    min_length = min(d['value'] for d in context_data)
                    context_stats_text += f"- å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦: {avg_length:.0f}å­—ç¬¦\n"
                    context_stats_text += f"- æœ€é•¿ä¸Šä¸‹æ–‡: {max_length:.0f}å­—ç¬¦\n"
                    context_stats_text += f"- æœ€çŸ­ä¸Šä¸‹æ–‡: {min_length:.0f}å­—ç¬¦"
                else:
                    context_stats_text += "æš‚æ— ä¸Šä¸‹æ–‡æ•°æ®"
            else:
                context_stats_text += "æš‚æ— ä¸Šä¸‹æ–‡é•¿åº¦æ•°æ®"

            return response_time_text, query_stats_text, retrieval_quality_text, context_stats_text

        except Exception as e:
            self._logger.error("åˆ·æ–°RAGæŒ‡æ ‡å¤±è´¥", exception=e)
            error_msg = "âŒ RAGæŒ‡æ ‡åˆ·æ–°å¤±è´¥"
            return error_msg, error_msg, error_msg, error_msg

    def _refresh_system_resources(self) -> Tuple[str, str, str, str]:
        """åˆ·æ–°ç³»ç»Ÿèµ„æºä¿¡æ¯

        Returns:
            (CPUå†…å­˜, ç£ç›˜ä½¿ç”¨, ç½‘ç»œç»Ÿè®¡, è¿›ç¨‹ä¿¡æ¯)
        """
        try:
            # å°è¯•è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
            try:
                import psutil

                # CPUå’Œå†…å­˜
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                cpu_memory_text = f"ğŸ–¥ï¸ **CPUå’Œå†…å­˜ä½¿ç”¨ç‡**\n" \
                                f"- CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%\n" \
                                f"- å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%\n" \
                                f"- å¯ç”¨å†…å­˜: {memory.available / (1024**3):.1f}GB\n" \
                                f"- æ€»å†…å­˜: {memory.total / (1024**3):.1f}GB"

                # ç£ç›˜ä½¿ç”¨
                disk = psutil.disk_usage('/')
                disk_text = f"ğŸ’¾ **ç£ç›˜ä½¿ç”¨æƒ…å†µ**\n" \
                          f"- ç£ç›˜ä½¿ç”¨ç‡: {disk.percent:.1f}%\n" \
                          f"- å¯ç”¨ç©ºé—´: {disk.free / (1024**3):.1f}GB\n" \
                          f"- æ€»ç©ºé—´: {disk.total / (1024**3):.1f}GB"

                # ç½‘ç»œç»Ÿè®¡ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
                network_text = f"ğŸŒ **ç½‘ç»œç»Ÿè®¡**\n" \
                             f"- ç½‘ç»œæ¥å£æ•°: {len(psutil.net_if_addrs())}\n" \
                             f"- ç½‘ç»œè¿æ¥æ•°: {len(psutil.net_connections())}"

                # è¿›ç¨‹ä¿¡æ¯
                process = psutil.Process()
                process_text = f"âš™ï¸ **å½“å‰è¿›ç¨‹ä¿¡æ¯**\n" \
                             f"- è¿›ç¨‹ID: {process.pid}\n" \
                             f"- è¿›ç¨‹å†…å­˜: {process.memory_info().rss / (1024**2):.1f}MB\n" \
                             f"- è¿›ç¨‹CPU: {process.cpu_percent():.1f}%\n" \
                             f"- çº¿ç¨‹æ•°: {process.num_threads()}"

            except ImportError:
                # psutilä¸å¯ç”¨æ—¶çš„fallback
                cpu_memory_text = "ğŸ–¥ï¸ **CPUå’Œå†…å­˜ä½¿ç”¨ç‡**\nç³»ç»Ÿç›‘æ§ä¸å¯ç”¨ï¼ˆç¼ºå°‘psutilåŒ…ï¼‰"
                disk_text = "ğŸ’¾ **ç£ç›˜ä½¿ç”¨æƒ…å†µ**\nç£ç›˜ç›‘æ§ä¸å¯ç”¨ï¼ˆç¼ºå°‘psutilåŒ…ï¼‰"
                network_text = "ğŸŒ **ç½‘ç»œç»Ÿè®¡**\nç½‘ç»œç›‘æ§ä¸å¯ç”¨ï¼ˆç¼ºå°‘psutilåŒ…ï¼‰"
                process_text = "âš™ï¸ **è¿›ç¨‹ä¿¡æ¯**\nè¿›ç¨‹ç›‘æ§ä¸å¯ç”¨ï¼ˆç¼ºå°‘psutilåŒ…ï¼‰"

            return cpu_memory_text, disk_text, network_text, process_text

        except Exception as e:
            self._logger.error("åˆ·æ–°ç³»ç»Ÿèµ„æºå¤±è´¥", exception=e)
            error_msg = "âŒ ç³»ç»Ÿèµ„æºä¿¡æ¯è·å–å¤±è´¥"
            return error_msg, error_msg, error_msg, error_msg


def create_performance_dashboard(
    metrics_service: Optional[MetricsService] = None,
    health_service: Optional[HealthCheckService] = None,
    logger_service: Optional[ILoggingService] = None
) -> PerformanceDashboard:
    """åˆ›å»ºæ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿å®ä¾‹

    Args:
        metrics_service: æŒ‡æ ‡æœåŠ¡å®ä¾‹
        health_service: å¥åº·æ£€æŸ¥æœåŠ¡å®ä¾‹
        logger_service: æ—¥å¿—æœåŠ¡å®ä¾‹

    Returns:
        æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿å®ä¾‹
    """
    return PerformanceDashboard(
        metrics_service=metrics_service,
        health_service=health_service,
        logger_service=logger_service
    )