"""
æ–‡æ¡£å¤„ç†æœåŠ¡
å°è£…PDFæ–‡æ¡£çš„ä¸Šä¼ ã€å¤„ç†ã€å‘é‡åŒ–ç­‰æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
"""

import os
import tempfile
from pathlib import Path
from typing import Optional, Tuple, List
from datetime import datetime

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# ä½¿ç”¨æ–°çš„åŸºç¡€è®¾æ–½æœåŠ¡
from src.infrastructure.config.config_migration_adapter import get_legacy_config
from src.infrastructure.utilities import get_utility_service
from src.infrastructure import get_logger
from src.shared.state.application_state import app_state, FileInfo


class DocumentService:
    """æ–‡æ¡£å¤„ç†æœåŠ¡"""

    def __init__(self, model_service=None, config_service=None, logger_service=None, utility_service=None):
        """åˆå§‹åŒ–æ–‡æ¡£æœåŠ¡

        Args:
            model_service: æ¨¡å‹ç®¡ç†æœåŠ¡å®ä¾‹ï¼Œç”¨äºä¾èµ–æ³¨å…¥
            config_service: é…ç½®æœåŠ¡å®ä¾‹
            logger_service: æ—¥å¿—æœåŠ¡å®ä¾‹
            utility_service: å·¥å…·æœåŠ¡å®ä¾‹
        """
        self.model_service = model_service

        # è·å–æœåŠ¡å®ä¾‹ (æ”¯æŒä¾èµ–æ³¨å…¥)
        if config_service:
            # å¦‚æœæä¾›äº†ConfigurationServiceï¼Œä½¿ç”¨ConfigMigrationAdapteré€‚é…
            from src.infrastructure.config.config_migration_adapter import ConfigMigrationAdapter
            self.config = ConfigMigrationAdapter(config_service)
        else:
            self.config = get_legacy_config()
        self.logger = logger_service or get_logger()
        self.utility = utility_service or get_utility_service()

        # ä½¿ç”¨é…ç½®æœåŠ¡åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.CHUNK_SIZE,
            chunk_overlap=self.config.CHUNK_OVERLAP,
            length_function=len,
        )

        self.logger.info("DocumentService åˆå§‹åŒ–å®Œæˆ", extra={
            "chunk_size": self.config.CHUNK_SIZE,
            "chunk_overlap": self.config.CHUNK_OVERLAP
        })

    def process_pdf(self, file) -> str:
        """
        å¤„ç†PDFæ–‡ä»¶å¹¶åˆ›å»ºå‘é‡æ•°æ®åº“

        Args:
            file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡

        Returns:
            å¤„ç†ç»“æœæ¶ˆæ¯
        """
        self.logger.info("å¼€å§‹å¤„ç†PDFæ–‡ä»¶", extra={"file": str(file)})

        if file is None:
            self.logger.warning("æœªæä¾›æ–‡ä»¶")
            return "âŒ è¯·é€‰æ‹©ä¸€ä¸ª PDF æ–‡ä»¶"

        try:
            # è·å–æ–‡ä»¶è·¯å¾„å’Œåç§°
            file_path, file_name = self._get_file_info(file)

            self.logger.info("è·å–æ–‡ä»¶ä¿¡æ¯", extra={
                "file_path": file_path,
                "file_name": file_name
            })

            # éªŒè¯æ–‡ä»¶
            if not self._validate_file(file_path):
                return f"âŒ æ–‡ä»¶éªŒè¯å¤±è´¥: {file_path}"

            self.logger.info("æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œå¼€å§‹å¤„ç†æ–‡æ¡£")

            # åŠ è½½å¹¶å¤„ç†PDF
            documents = self._load_pdf(file_path)
            if not documents:
                return "âŒ PDF æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–"

            self.logger.info("æˆåŠŸåŠ è½½æ–‡æ¡£", extra={"pages": len(documents)})

            # åˆ†å‰²æ–‡æ¡£
            texts = self._split_documents(documents)
            self.logger.info("æ–‡æ¡£åˆ†å‰²å®Œæˆ", extra={"chunks": len(texts)})

            # åˆ›å»ºå‘é‡å­˜å‚¨
            success = self._create_vector_store(texts)
            if not success:
                return "âŒ å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥"

            # æ›´æ–°æ–‡ä»¶è®°å½•
            self._update_file_record(file_name, len(documents), len(texts))

            self.logger.info("æ–‡æ¡£å¤„ç†å®Œæˆ", extra={
                "file_name": file_name,
                "pages": len(documents),
                "chunks": len(texts)
            })
            return f"âœ… æ–‡æ¡£ '{file_name}' å¤„ç†å®Œæˆï¼\\nğŸ“„ é¡µæ•°: {len(documents)}\\nğŸ“ æ–‡æ¡£ç‰‡æ®µ: {len(texts)}"

        except Exception as e:
            error_msg = f"âŒ å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            self.logger.error("æ–‡æ¡£å¤„ç†å¤±è´¥", exception=e, extra={"file": str(file)})
            return error_msg

    def process_pdf_and_update_status(self, file, selected_model: str) -> Tuple[str, str, str, str]:
        """
        å¤„ç†PDFå¹¶æ›´æ–°ç³»ç»ŸçŠ¶æ€

        Args:
            file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
            selected_model: é€‰æ‹©çš„æ¨¡å‹

        Returns:
            (upload_status, model_status, system_status, file_list)
        """
        try:
            # æ›´æ–°å½“å‰æ¨¡å‹
            app_state.current_model = selected_model

            # å¤„ç†PDF
            upload_status = self.process_pdf(file)

            # è·å–æ›´æ–°åçš„çŠ¶æ€
            model_status = f"å½“å‰æ¨¡å‹: {app_state.current_model} (å°±ç»ª)"
            system_status = self._get_system_status()
            file_list = self._get_uploaded_files_display()

            return upload_status, model_status, system_status, file_list

        except Exception as e:
            error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
            return error_msg, "æ¨¡å‹çŠ¶æ€è·å–å¤±è´¥", "ç³»ç»ŸçŠ¶æ€è·å–å¤±è´¥", "æ–‡ä»¶åˆ—è¡¨è·å–å¤±è´¥"

    def _get_file_info(self, file) -> Tuple[str, str]:
        """è·å–æ–‡ä»¶è·¯å¾„å’Œåç§°"""
        if hasattr(file, 'name'):
            file_path = file.name
            file_name = Path(file_path).name
        else:
            file_path = str(file)
            file_name = Path(file_path).name
        return file_path, file_name

    def _validate_file(self, file_path: str) -> bool:
        """éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            self.logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False

        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not self.utility.validate_file_type(file_path, self.config.ALLOWED_FILE_TYPES):
            self.logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path}")
            return False

        # éªŒè¯æ–‡ä»¶å¤§å°
        if not self.utility.validate_file_size(file_path, self.config.MAX_FILE_SIZE_MB):
            self.logger.error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_path}")
            return False

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œï¼ˆç”¨äºå»é‡æ£€æµ‹ï¼‰
        file_hash = self.utility.calculate_file_hash(file_path)
        if file_hash:
            self.logger.debug(f"æ–‡ä»¶å“ˆå¸Œè®¡ç®—å®Œæˆ: {file_path} -> {file_hash[:8]}...")

        return True

    def _load_pdf(self, file_path: str):
        """åŠ è½½PDFæ–‡æ¡£"""
        self.logger.info("æ­£åœ¨åŠ è½½ PDF...")
        loader = PyPDFLoader(file_path)
        documents = loader.load()
        return documents

    def _split_documents(self, documents):
        """åˆ†å‰²æ–‡æ¡£"""
        self.logger.info("æ­£åœ¨åˆ†å‰²æ–‡æ¡£...")
        texts = self.text_splitter.split_documents(documents)
        return texts

    def _create_vector_store(self, texts) -> bool:
        """åˆ›å»ºæˆ–æ›´æ–°å‘é‡å­˜å‚¨"""
        try:
            self.logger.info("æ­£åœ¨åˆ›å»ºåµŒå…¥...")

            # åˆ›å»ºåµŒå…¥æ¨¡å‹
            embeddings = self._create_embeddings()
            if not embeddings:
                return False

            self.logger.info("æ­£åœ¨å¤„ç†å‘é‡æ•°æ®åº“...")

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å‘é‡æ•°æ®åº“
            if app_state.vectorstore is not None:
                self.logger.info("æ£€æµ‹åˆ°å·²æœ‰å‘é‡æ•°æ®åº“ï¼Œå°†æ·»åŠ æ–°æ–‡æ¡£...")
                try:
                    app_state.vectorstore.add_documents(texts)
                    self.logger.info("âœ… æ–°æ–‡æ¡£å·²æ·»åŠ åˆ°ç°æœ‰å‘é‡æ•°æ®åº“")
                except Exception as e:
                    self.logger.error("æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“å¤±è´¥", exception=e, extra={"file": str(file)})
                    # é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“
                    self.logger.info("æ­£åœ¨é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“...")
                    app_state.vectorstore = Chroma.from_documents(
                        documents=texts,
                        embedding=embeddings
                    )
                    self.logger.info("âœ… å‘é‡æ•°æ®åº“é‡æ–°åˆ›å»ºæˆåŠŸ")
            else:
                self.logger.info("åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“...")
                app_state.vectorstore = Chroma.from_documents(
                    documents=texts,
                    embedding=embeddings
                )
                self.logger.info("âœ… å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸ")

            return True

        except Exception as e:
            self.logger.error("å‘é‡å­˜å‚¨åˆ›å»ºå¤±è´¥", exception=e)
            return False

    def _create_embeddings(self):
        """åˆ›å»ºåµŒå…¥æ¨¡å‹"""
        try:
            embeddings = GoogleGenerativeAIEmbeddings(
                model="models/embedding-001",
                request_timeout=120
            )
            self.logger.info("âœ… Embedding æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            return embeddings
        except Exception as e:
            self.logger.error("Embedding æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ", exception=e)
            try:
                embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/text-embedding-004",
                    request_timeout=120
                )
                self.logger.info("âœ… ä½¿ç”¨å¤‡ç”¨ embedding æ¨¡å‹æˆåŠŸ")
                return embeddings
            except Exception as e2:
                self.logger.error("æ— æ³•åˆå§‹åŒ– embedding æ¨¡å‹", exception=e2)
                return None

    def _update_file_record(self, file_name: str, pages: int, chunks: int):
        """æ›´æ–°æ–‡ä»¶è®°å½•"""
        file_info = FileInfo(
            name=file_name,
            upload_time=datetime.now(),
            pages=pages,
            chunks=chunks,
            model=app_state.current_model
        )
        app_state.add_uploaded_file(file_info)

    def _get_system_status(self) -> str:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            state_info = app_state.get_state_info()

            status_parts = [
                f"ğŸ¤– å½“å‰æ¨¡å‹: {state_info['current_model']}",
                f"ğŸ“Š çŠ¶æ€: {'å°±ç»ª' if state_info['qa_chain_initialized'] else 'æœªåŠ è½½'}",
                f"ğŸ“š å·²ä¸Šä¼ æ–‡æ¡£: {state_info['uploaded_files_count']} ä¸ª",
                f"ğŸ”§ å‘é‡æ•°æ®åº“: {'å·²åˆå§‹åŒ–' if state_info['vectorstore_initialized'] else 'æœªåˆå§‹åŒ–'}",
                f"ğŸ• æœ€åæ›´æ–°: {datetime.fromisoformat(state_info['last_update']).strftime('%H:%M:%S')}"
            ]

            return "\\n".join(status_parts)

        except Exception as e:
            return f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}"

    def _get_uploaded_files_display(self) -> str:
        """è·å–ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨æ˜¾ç¤º"""
        try:
            files = app_state.get_uploaded_files()

            if not files:
                return "æš‚æ— å·²ä¸Šä¼ çš„æ–‡ä»¶"

            file_list = ["## ğŸ“ å·²ä¸Šä¼ çš„æ–‡ä»¶\\n"]

            for i, file_info in enumerate(files, 1):
                upload_time = file_info.upload_time.strftime("%Y-%m-%d %H:%M:%S")
                file_list.append(
                    f"**{i}. {file_info.name}**\\n"
                    f"   - ğŸ“… ä¸Šä¼ æ—¶é—´: {upload_time}\\n"
                    f"   - ğŸ“„ é¡µæ•°: {file_info.pages}\\n"
                    f"   - ğŸ“ æ–‡æ¡£ç‰‡æ®µ: {file_info.chunks}\\n"
                    f"   - ğŸ¤– å¤„ç†æ¨¡å‹: {file_info.model}\\n"
                )

            return "\\n".join(file_list)

        except Exception as e:
            return f"âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}"

    def get_uploaded_files_count(self) -> int:
        """è·å–å·²ä¸Šä¼ æ–‡ä»¶æ•°é‡"""
        return len(app_state.get_uploaded_files())

    def clear_uploaded_files(self):
        """æ¸…ç©ºä¸Šä¼ æ–‡ä»¶è®°å½•"""
        app_state.clear_uploaded_files()