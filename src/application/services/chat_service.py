"""
èŠå¤©æœåŠ¡
å°è£…èŠå¤©é—®ç­”ã€QAé“¾ç®¡ç†ç­‰æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
"""

from typing import List, Tuple, Optional
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

from src.application.services.memory_service import MemoryService
from src.application.services.rerank_service import RerankService
from src.application.services.rerank_retriever import RerankRetriever
from src.shared.state.application_state import app_state
from src.infrastructure import get_logger, get_config
from src.infrastructure.utilities import get_utility_service


class ChatService:
    """èŠå¤©æœåŠ¡"""

    def __init__(self, model_service=None, memory_service=None, config_service=None, logger_service=None):
        """åˆå§‹åŒ–èŠå¤©æœåŠ¡

        Args:
            model_service: æ¨¡å‹ç®¡ç†æœåŠ¡å®ä¾‹ï¼Œç”¨äºä¾èµ–æ³¨å…¥
            memory_service: å†…å­˜ç®¡ç†æœåŠ¡å®ä¾‹
            config_service: é…ç½®æœåŠ¡å®ä¾‹
            logger_service: æ—¥å¿—æœåŠ¡å®ä¾‹
        """
        self.model_service = model_service
        self.config = config_service or get_config()
        self.logger = logger_service or get_logger()
        self.utility = get_utility_service()

        # å†…å­˜ç®¡ç†æœåŠ¡
        self.memory_service = memory_service or MemoryService(
            config_service=config_service,
            logger_service=logger_service
        )

        # é‡æ’åºæœåŠ¡
        self.rerank_service = RerankService(self.config)

        # é‡æ’åºé…ç½®
        self.use_rerank = self.config.get_value("use_rerank", True)

        self.logger.info("ChatService åˆå§‹åŒ–å®Œæˆ", extra={
            "memory_service_type": type(self.memory_service).__name__,
            "use_rerank": self.use_rerank
        })

    def chat_with_pdf(self, message: str, history: List[List[str]]) -> Tuple[str, List[List[str]]]:
        """
        ä¸PDFæ–‡æ¡£èŠå¤©

        Args:
            message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            history: å¯¹è¯å†å²

        Returns:
            (å›å¤æ¶ˆæ¯, æ›´æ–°åçš„å†å²)
        """
        try:
            if not message.strip():
                self.logger.warning("ç”¨æˆ·è¾“å…¥ä¸ºç©º")
                return "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚", history

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„é—®ç­”é“¾
            qa_chain = self._get_or_create_qa_chain()
            if not qa_chain:
                error_msg = "âŒ ç³»ç»Ÿå°šæœªå°±ç»ªï¼Œè¯·å…ˆä¸Šä¼ PDFæ–‡æ¡£ã€‚"
                self.logger.warning("QAé“¾æœªå°±ç»ª")
                return error_msg, history

            self.logger.info("å¼€å§‹å¤„ç†ç”¨æˆ·é—®é¢˜", extra={
                "question_preview": self.utility.truncate_text(message, 100)
            })

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†…å­˜
            self.memory_service.add_message_to_current_session("user", message)

            # è·å–å¯¹è¯ä¸Šä¸‹æ–‡ä»¥å¢å¼ºRAGæŸ¥è¯¢
            conversation_context = self.memory_service.get_current_session_context(include_messages=3)

            # æ„å»ºå¢å¼ºçš„æŸ¥è¯¢ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ï¼‰
            enhanced_query = self._build_enhanced_query(message, conversation_context)

            # æ‰§è¡Œé—®ç­”
            try:
                result = qa_chain({"query": enhanced_query})
                answer = result["result"]

                # å¤„ç†å‚è€ƒæ¥æº
                source_documents = result.get("source_documents", [])
                if source_documents:
                    sources = []
                    for doc in source_documents[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ¥æº
                        src = doc.metadata.get("source", "æœªçŸ¥")
                        if "/" in src:
                            src = src.split("/")[-1]  # åªå–æ–‡ä»¶å
                        sources.append(src)

                    # å»é‡å¹¶æ·»åŠ åˆ°ç­”æ¡ˆæœ«å°¾
                    unique_sources = list(dict.fromkeys(sources))
                    if unique_sources:
                        answer += f"\n\nğŸ“š **å‚è€ƒæ¥æº**: {', '.join(unique_sources)}"

                # æ·»åŠ AIå›å¤åˆ°å†…å­˜
                self.memory_service.add_message_to_current_session("assistant", answer)

                self.logger.info("é—®ç­”å¤„ç†æˆåŠŸ", extra={
                    "answer_preview": self.utility.truncate_text(answer, 100),
                    "session_id": self.memory_service.current_session_id,
                    "source_count": len(source_documents)
                })

            except Exception as e:
                self.logger.error("é—®ç­”æ‰§è¡Œå¤±è´¥", exception=e)
                answer = f"âŒ å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

                # è®°å½•é”™è¯¯åˆ°å†…å­˜
                self.memory_service.add_message_to_current_session("assistant", answer, {
                    "error": True,
                    "error_type": type(e).__name__
                })

            # æ›´æ–°å¯¹è¯å†å²
            history.append([message, answer])

            # å®šæœŸä¿å­˜ä¼šè¯ï¼šæŒ‰æœåŠ¡å™¨ç«¯ MemoryService çš„æ€»æ¶ˆæ¯è®¡æ•°åˆ¤æ–­
            try:
                total_msgs = self.memory_service.get_current_session_info().get("message_count", 0)
                # ä¸€é—®ä¸€ç­”è®¡ä¸º 2 æ¡æ¶ˆæ¯ï¼›å½“å¯¹è¯è½®æ¬¡è¾¾åˆ° 5ï¼ˆå³ 10 æ¡æ¶ˆæ¯ï¼‰æ—¶ä¿å­˜
                if total_msgs % 10 == 0 and total_msgs != 0:
                    self.logger.info("è¾¾åˆ° 5 è½®å¯¹è¯ï¼Œè‡ªåŠ¨æŒä¹…åŒ–ä¼šè¯", extra={
                        "total_messages": total_msgs,
                        "session_id": self.memory_service.current_session_id
                    })
                    self.memory_service.save_current_session()
            except Exception as e:
                self.logger.error("è‡ªåŠ¨ä¿å­˜ä¼šè¯å¤±è´¥", exception=e)

            return answer, history

        except Exception as e:
            error_msg = f"âŒ èŠå¤©æœåŠ¡å¼‚å¸¸: {str(e)}"
            self.logger.error("èŠå¤©æœåŠ¡å¼‚å¸¸", exception=e)
            history.append([message, error_msg])
            return error_msg, history

    def _build_enhanced_query(self, message: str, context: str) -> str:
        """æ„å»ºå¢å¼ºçš„æŸ¥è¯¢ï¼ŒåŒ…å«å¯¹è¯ä¸Šä¸‹æ–‡"""
        if not context.strip():
            return message

        # å¦‚æœä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œæˆªå–æœ€ç›¸å…³çš„éƒ¨åˆ†
        if len(context) > 500:
            context = self.utility.truncate_text(context, 500)

        enhanced_query = f"""
åŸºäºä»¥ä¸‹å¯¹è¯ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
{context}

å½“å‰é—®é¢˜ï¼š{message}

è¯·è€ƒè™‘å¯¹è¯ä¸Šä¸‹æ–‡æ¥æä¾›æ›´å‡†ç¡®å’Œç›¸å…³çš„å›ç­”ã€‚
"""
        return enhanced_query

    def _get_or_create_qa_chain(self):
        """è·å–æˆ–åˆ›å»ºé—®ç­”é“¾"""
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰é—®ç­”é“¾
        if app_state.qa_chain is not None:
            return app_state.qa_chain

        # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡å­˜å‚¨
        if app_state.vectorstore is None:
            self.logger.warning("å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
            return None

        try:
            # åˆ›å»ºLLM
            llm = self._create_llm()
            if not llm:
                return None

            # è·å–å†…å­˜å˜é‡ä»¥é›†æˆåˆ°é—®ç­”é“¾ä¸­
            memory_variables = self.memory_service.get_memory_variables()

            # åˆ›å»ºæ£€ç´¢å™¨
            retriever = self._create_retriever()
            if not retriever:
                self.logger.error("æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥")
                return None

            # åˆ›å»ºé—®ç­”é“¾
            app_state.qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=retriever,
                chain_type_kwargs={
                    "prompt": self._create_prompt_template()
                },
                return_source_documents=True
            )

            self.logger.info("é—®ç­”é“¾åˆ›å»ºæˆåŠŸ", extra={
                "use_rerank": self.use_rerank
            })
            return app_state.qa_chain

        except Exception as e:
            self.logger.error("é—®ç­”é“¾åˆ›å»ºå¤±è´¥", exception=e)
            return None

    def _create_retriever(self):
        """åˆ›å»ºæ£€ç´¢å™¨"""
        try:
            if self.use_rerank:
                # åˆ›å»ºåŸºç¡€æ£€ç´¢å™¨
                base_retriever = app_state.vectorstore.as_retriever(
                    search_kwargs={"k": int(self.config.get_value("rerank_initial_k", 8))}
                )

                # åˆ›å»ºé‡æ’åºæ£€ç´¢å™¨
                rerank_retriever = RerankRetriever(
                    base_retriever=base_retriever,
                    rerank_service=self.rerank_service,
                    final_k=int(self.config.get_value("rerank_final_k", 4))
                )

                self.logger.info("é‡æ’åºæ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
                return rerank_retriever
            else:
                # ä½¿ç”¨åŸºç¡€æ£€ç´¢å™¨
                basic_retriever = app_state.vectorstore.as_retriever(
                    search_kwargs={"k": self.config.get_value("similarity_top_k", 4)}
                )

                self.logger.info("åŸºç¡€æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
                return basic_retriever

        except Exception as e:
            self.logger.error("æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥", exception=e)
            return None

    def _create_llm(self):
        """åˆ›å»ºè¯­è¨€æ¨¡å‹"""
        try:
            current_model = app_state.current_model
            self.logger.info("åˆ›å»ºLLM", extra={"model": current_model})

            llm = ChatGoogleGenerativeAI(
                model=current_model,
                temperature=0.3,
                convert_system_message_to_human=True
            )

            # æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ç”¨
            test_response = llm.invoke("æµ‹è¯•")
            self.logger.info("LLMåˆ›å»ºæˆåŠŸ", extra={"model": current_model})
            return llm

        except Exception as e:
            self.logger.error("LLMåˆ›å»ºå¤±è´¥", exception=e)
            return None

    def _create_prompt_template(self) -> PromptTemplate:
        """åˆ›å»ºæç¤ºæ¨¡æ¿"""
        template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. ä»…åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡å†…å®¹å›ç­”é—®é¢˜
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ä¸”æœ‰å¸®åŠ©
4. å¦‚æœå¯èƒ½ï¼Œè¯·å¼•ç”¨å…·ä½“çš„æ–‡æ¡£å†…å®¹
5. ä½¿ç”¨ä¸­æ–‡å›ç­”
6. è€ƒè™‘å¯¹è¯çš„è¿ç»­æ€§ï¼Œå¦‚æœé—®é¢˜æ¶‰åŠä¹‹å‰çš„è®¨è®ºå†…å®¹ï¼Œè¯·é€‚å½“å…³è”

ä¸Šä¸‹æ–‡æ–‡æ¡£ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š"""

        return PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

    def reset_qa_chain(self):
        """é‡ç½®é—®ç­”é“¾"""
        try:
            app_state.qa_chain = None
            self.logger.info("é—®ç­”é“¾å·²é‡ç½®")
        except Exception as e:
            self.logger.error("é‡ç½®é—®ç­”é“¾å¤±è´¥", exception=e)

    def is_ready(self) -> bool:
        """æ£€æŸ¥èŠå¤©æœåŠ¡æ˜¯å¦å°±ç»ª"""
        return (app_state.vectorstore is not None and
                app_state.qa_chain is not None)

    def get_conversation_history(self) -> List[dict]:
        """è·å–å¯¹è¯å†å²"""
        try:
            chat_messages = self.memory_service.get_current_session_history()
            # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            history = []
            for msg in chat_messages:
                role = "human" if msg.role == "user" else "ai"
                history.append({
                    "role": role,
                    "content": msg.content,
                    "timestamp": msg.timestamp,
                    "metadata": msg.metadata
                })
            return history
        except Exception as e:
            self.logger.error("è·å–å¯¹è¯å†å²å¤±è´¥", exception=e)
            return []

    def clear_conversation_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        try:
            self.memory_service.clear_current_session()
            self.logger.info("å¯¹è¯å†å²å·²æ¸…ç©º")
        except Exception as e:
            self.logger.error("æ¸…ç©ºå¯¹è¯å†å²å¤±è´¥", exception=e)

    def reset_conversation_session(self) -> str:
        """é‡ç½®å¯¹è¯ä¼šè¯"""
        try:
            new_session_id = self.memory_service.reset_current_session()
            self.logger.info("å¯¹è¯ä¼šè¯å·²é‡ç½®", extra={"new_session_id": new_session_id})
            return new_session_id
        except Exception as e:
            self.logger.error("é‡ç½®å¯¹è¯ä¼šè¯å¤±è´¥", exception=e)
            return ""

    def save_current_conversation(self) -> bool:
        """ä¿å­˜å½“å‰å¯¹è¯"""
        try:
            return self.memory_service.save_current_session()
        except Exception as e:
            self.logger.error("ä¿å­˜å½“å‰å¯¹è¯å¤±è´¥", exception=e)
            return False

    def get_conversation_summary(self) -> str:
        """è·å–å¯¹è¯æ‘˜è¦"""
        try:
            session_info = self.memory_service.get_current_session_info()
            message_count = session_info.get("message_count", 0)

            if message_count == 0:
                return "æš‚æ— å¯¹è¯å†…å®¹"

            user_messages = 0
            assistant_messages = 0

            history = self.get_conversation_history()
            for msg in history:
                if msg["role"] == "human":
                    user_messages += 1
                else:
                    assistant_messages += 1

            return f"æœ¬æ¬¡å¯¹è¯åŒ…å« {message_count} æ¡æ¶ˆæ¯ï¼ˆç”¨æˆ· {user_messages} æ¡ï¼ŒåŠ©æ‰‹ {assistant_messages} æ¡ï¼‰"

        except Exception as e:
            self.logger.error("è·å–å¯¹è¯æ‘˜è¦å¤±è´¥", exception=e)
            return "è·å–å¯¹è¯æ‘˜è¦å¤±è´¥"

    def get_service_status(self) -> dict:
        """è·å–èŠå¤©æœåŠ¡çŠ¶æ€"""
        try:
            memory_status = self.memory_service.get_service_status()

            return {
                "service_name": "ChatService",
                "status": "active" if self.is_ready() else "not_ready",
                "qa_chain_ready": app_state.qa_chain is not None,
                "vectorstore_ready": app_state.vectorstore is not None,
                "current_model": app_state.current_model,
                "memory_service": memory_status
            }

        except Exception as e:
            self.logger.error("è·å–æœåŠ¡çŠ¶æ€å¤±è´¥", exception=e)
            return {
                "service_name": "ChatService",
                "status": "error",
                "error": str(e)
            }